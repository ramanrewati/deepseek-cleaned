{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11b0842181834b3ab8496d12cd863824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1655ce86979844398ac438bb15abe9a9",
              "IPY_MODEL_02d794b025ef4fc2816fbf3afa89f87c",
              "IPY_MODEL_c03b3255f38b493eb2c4a19893af9fd9"
            ],
            "layout": "IPY_MODEL_b9127b7e08274117b0933a6b20b9663d"
          }
        },
        "1655ce86979844398ac438bb15abe9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b27d4ec2ab2d4ae5beb30ef0933c7c62",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf44bfbf3df4800aa985fa6356d9a50",
            "value": "Fetching 11 files: 100%"
          }
        },
        "02d794b025ef4fc2816fbf3afa89f87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e68902f07c4e3cb8692322c2f011af",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3021d57b411549cc91a694921f6b54ce",
            "value": 11
          }
        },
        "c03b3255f38b493eb2c4a19893af9fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c41106deea4dcf90ce4f435ae40486",
            "placeholder": "​",
            "style": "IPY_MODEL_06c64f02b7d5432b82c314c10e67c3b9",
            "value": " 11/11 [03:31&lt;00:00, 31.54s/it]"
          }
        },
        "b9127b7e08274117b0933a6b20b9663d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27d4ec2ab2d4ae5beb30ef0933c7c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf44bfbf3df4800aa985fa6356d9a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6e68902f07c4e3cb8692322c2f011af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3021d57b411549cc91a694921f6b54ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2c41106deea4dcf90ce4f435ae40486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c64f02b7d5432b82c314c10e67c3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9177fb7fa09e491dbf6a7b88ecf78380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e13925b4018441595defa5ce79090ab",
              "IPY_MODEL_cf8ac975033b4611b06d6fec2128123a",
              "IPY_MODEL_f34ade792e6b45e2a4382abcbd061640"
            ],
            "layout": "IPY_MODEL_08b57f774af54e03ad6808954f12da8b"
          }
        },
        "0e13925b4018441595defa5ce79090ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9262e4a304544dbd91e7e032f53ca987",
            "placeholder": "​",
            "style": "IPY_MODEL_bdd982dbae3b438a85e700c2b212ab80",
            "value": "generation_config.json: 100%"
          }
        },
        "cf8ac975033b4611b06d6fec2128123a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1796d44851d848cfaf5905c502e32259",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab1cc2b16f384d79906efc589f76c9b6",
            "value": 181
          }
        },
        "f34ade792e6b45e2a4382abcbd061640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b00109ab1fe425fa63935d89ffc1feb",
            "placeholder": "​",
            "style": "IPY_MODEL_7f30cf9da16a43b187505db214ae4022",
            "value": " 181/181 [00:00&lt;00:00, 1.15kB/s]"
          }
        },
        "08b57f774af54e03ad6808954f12da8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9262e4a304544dbd91e7e032f53ca987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd982dbae3b438a85e700c2b212ab80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1796d44851d848cfaf5905c502e32259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1cc2b16f384d79906efc589f76c9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b00109ab1fe425fa63935d89ffc1feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f30cf9da16a43b187505db214ae4022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e110699fc064bfc88ba50ae52fadb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8477e1656abc439cb121354e7a1cba45",
              "IPY_MODEL_be84522b7fc3401fa35e7d722d0935f9",
              "IPY_MODEL_aea5c90397c345ceb5e8c82287a0fb4b"
            ],
            "layout": "IPY_MODEL_2a03ba4bc8b84a7bbfd646bf771e52c2"
          }
        },
        "8477e1656abc439cb121354e7a1cba45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78eeb3b438444cec8cf015ab2d15fade",
            "placeholder": "​",
            "style": "IPY_MODEL_92cfa354497f483eae05e372eff6ced3",
            "value": "README.md: 100%"
          }
        },
        "be84522b7fc3401fa35e7d722d0935f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97dcd3842d7f415790b0b279828950e1",
            "max": 18582,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_684db16cc44540ec8146a3a30434ec7d",
            "value": 18582
          }
        },
        "aea5c90397c345ceb5e8c82287a0fb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac11a98994644ec87e4e36f1f1752c6",
            "placeholder": "​",
            "style": "IPY_MODEL_93aad35ba2d14a48838834e8e9d665dc",
            "value": " 18.6k/18.6k [00:00&lt;00:00, 190kB/s]"
          }
        },
        "2a03ba4bc8b84a7bbfd646bf771e52c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78eeb3b438444cec8cf015ab2d15fade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92cfa354497f483eae05e372eff6ced3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97dcd3842d7f415790b0b279828950e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684db16cc44540ec8146a3a30434ec7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fac11a98994644ec87e4e36f1f1752c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93aad35ba2d14a48838834e8e9d665dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d1d5434caa14d4cbfa1373846a4ec95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a17c2c0461f447c9d56a8f08e2722c6",
              "IPY_MODEL_7520be07cc9e447793a7ae994f906fed",
              "IPY_MODEL_e28dd782f98949d5a9ed037f74e9f08f"
            ],
            "layout": "IPY_MODEL_0eece40ab32b4823b47c641183a7b548"
          }
        },
        "1a17c2c0461f447c9d56a8f08e2722c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb486d80c2964438aaa154a01646ce40",
            "placeholder": "​",
            "style": "IPY_MODEL_202d791ee992434294fbe802d0d56381",
            "value": "LICENSE: 100%"
          }
        },
        "7520be07cc9e447793a7ae994f906fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25cb29d946ba40abbf786c06e699a577",
            "max": 1064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2337cc618d0f4a4688dfe74ebc9e57d2",
            "value": 1064
          }
        },
        "e28dd782f98949d5a9ed037f74e9f08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1768bf2af040497a91a7fe7a02d865c9",
            "placeholder": "​",
            "style": "IPY_MODEL_3e3c5c28949d46efaeec0698bd33908a",
            "value": " 1.06k/1.06k [00:00&lt;00:00, 9.74kB/s]"
          }
        },
        "0eece40ab32b4823b47c641183a7b548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb486d80c2964438aaa154a01646ce40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202d791ee992434294fbe802d0d56381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25cb29d946ba40abbf786c06e699a577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2337cc618d0f4a4688dfe74ebc9e57d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1768bf2af040497a91a7fe7a02d865c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e3c5c28949d46efaeec0698bd33908a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a0c80c95e55444b8b43dc75da10c9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2e6f1a7a11f4502a4856959c403bea3",
              "IPY_MODEL_be735e2ac5b5468f9a6ca68fb2bd99f9",
              "IPY_MODEL_178b351a72414c47b03e94de518e99a0"
            ],
            "layout": "IPY_MODEL_0f91772c8bf643e497f6ec05a7451625"
          }
        },
        "a2e6f1a7a11f4502a4856959c403bea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee9c79ff95f04e68a014deef73a63568",
            "placeholder": "​",
            "style": "IPY_MODEL_263bff5d4b1c48ec97f68bd01727fcd6",
            "value": "figures/benchmark.jpg: 100%"
          }
        },
        "be735e2ac5b5468f9a6ca68fb2bd99f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80e6ca7349540f184dfb1ab2a7d197a",
            "max": 777314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3630862d14c6467d996a366a7474d9a5",
            "value": 777314
          }
        },
        "178b351a72414c47b03e94de518e99a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cace4eac382143bcb7ded71ed02e2ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_8e4054b8bf4847c5bfc5b84f449dfac5",
            "value": " 777k/777k [00:00&lt;00:00, 2.90MB/s]"
          }
        },
        "0f91772c8bf643e497f6ec05a7451625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee9c79ff95f04e68a014deef73a63568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "263bff5d4b1c48ec97f68bd01727fcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c80e6ca7349540f184dfb1ab2a7d197a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3630862d14c6467d996a366a7474d9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cace4eac382143bcb7ded71ed02e2ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4054b8bf4847c5bfc5b84f449dfac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd9d0c40c4c241f8a71bb1d5e5ce10d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7502a55901142c99afd650319680161",
              "IPY_MODEL_d315daf872134d1199737631020f05a4",
              "IPY_MODEL_e9591eeec09546fea91854a075c47963"
            ],
            "layout": "IPY_MODEL_6e2b8fc2203a438ab874052490673d6c"
          }
        },
        "f7502a55901142c99afd650319680161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc92985363da4862a411cdc1bd8b70fb",
            "placeholder": "​",
            "style": "IPY_MODEL_45f14abc491b4d8a8842a41c22ff89cd",
            "value": "config.json: 100%"
          }
        },
        "d315daf872134d1199737631020f05a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3cca5ab55364564a076e0113e41bd73",
            "max": 680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9b43c331e604bf09598eb2dcb061607",
            "value": 680
          }
        },
        "e9591eeec09546fea91854a075c47963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cda426830dc4c6390bd3a33bc1a3fb0",
            "placeholder": "​",
            "style": "IPY_MODEL_e39079c3f5da41e5b5909aef438b5e99",
            "value": " 680/680 [00:00&lt;00:00, 6.18kB/s]"
          }
        },
        "6e2b8fc2203a438ab874052490673d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc92985363da4862a411cdc1bd8b70fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f14abc491b4d8a8842a41c22ff89cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3cca5ab55364564a076e0113e41bd73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b43c331e604bf09598eb2dcb061607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cda426830dc4c6390bd3a33bc1a3fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39079c3f5da41e5b5909aef438b5e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad169cdf838c42adacd1d1271da7e8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e988087f813d49529b7314eb8bba80dc",
              "IPY_MODEL_64bbe3cab6aa44d4a89cd381f49b360a",
              "IPY_MODEL_6b4fb3dee8b846fab8aa063ede7d1a5b"
            ],
            "layout": "IPY_MODEL_13404d8367764b1cb0df9281ddb4c2c3"
          }
        },
        "e988087f813d49529b7314eb8bba80dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e656e57b505b409abc43b554e8c3fb33",
            "placeholder": "​",
            "style": "IPY_MODEL_385fd67104d14e24aab3a421c90ae57d",
            "value": "model-00001-of-000002.safetensors: 100%"
          }
        },
        "64bbe3cab6aa44d4a89cd381f49b360a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bbd47a5b15f44c79c27f3900e8503eb",
            "max": 8606596466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e1c029908c6406cb61ad112efd7b9ec",
            "value": 8606596466
          }
        },
        "6b4fb3dee8b846fab8aa063ede7d1a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c85e2eacff84e9d9253aac350c8337a",
            "placeholder": "​",
            "style": "IPY_MODEL_2705fb0b5434480a9cefe00dce0b8280",
            "value": " 8.61G/8.61G [03:31&lt;00:00, 42.1MB/s]"
          }
        },
        "13404d8367764b1cb0df9281ddb4c2c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e656e57b505b409abc43b554e8c3fb33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385fd67104d14e24aab3a421c90ae57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bbd47a5b15f44c79c27f3900e8503eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1c029908c6406cb61ad112efd7b9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c85e2eacff84e9d9253aac350c8337a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2705fb0b5434480a9cefe00dce0b8280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a57cfcad70f45ee8da99a124560d0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f44e75f42f74ca9861c5b4e42a99199",
              "IPY_MODEL_6f0756455e8044f4a1ae045839790da6",
              "IPY_MODEL_811cf9087f48476d9d781a630e071ac2"
            ],
            "layout": "IPY_MODEL_9de941cd4c9643dbae0cd6e0be93176d"
          }
        },
        "7f44e75f42f74ca9861c5b4e42a99199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_909d9da289d04b9dbbf7f5b181143bbe",
            "placeholder": "​",
            "style": "IPY_MODEL_3d2c104a772d4fc99781f64ef1b3a72e",
            "value": "model-00002-of-000002.safetensors: 100%"
          }
        },
        "6f0756455e8044f4a1ae045839790da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c414afcc3de6491a8ddb6c737ad168ff",
            "max": 6624675384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de24194fe7684bd4bbd62b0aee3f86c3",
            "value": 6624675384
          }
        },
        "811cf9087f48476d9d781a630e071ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30d58907d2a94dfc8843208c238dbd64",
            "placeholder": "​",
            "style": "IPY_MODEL_b809942fc4a84914b0f68f14d2be4ad4",
            "value": " 6.62G/6.62G [02:42&lt;00:00, 41.7MB/s]"
          }
        },
        "9de941cd4c9643dbae0cd6e0be93176d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "909d9da289d04b9dbbf7f5b181143bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2c104a772d4fc99781f64ef1b3a72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c414afcc3de6491a8ddb6c737ad168ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de24194fe7684bd4bbd62b0aee3f86c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30d58907d2a94dfc8843208c238dbd64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b809942fc4a84914b0f68f14d2be4ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f9a42ec9bee47a4ac36a95036793fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d783448568647a6ad7123cd2c61e339",
              "IPY_MODEL_f2cc1fd0ab6249499c490222a318e773",
              "IPY_MODEL_fdffa29bc86d4e9ea884a75fcfb26db4"
            ],
            "layout": "IPY_MODEL_5bc1992df4104607bff1f1c3ec1146a6"
          }
        },
        "7d783448568647a6ad7123cd2c61e339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e355427768b4207a8f9b83e1b5a473f",
            "placeholder": "​",
            "style": "IPY_MODEL_ec82981e53bd4d16a3f9a24fa23785d0",
            "value": ".gitattributes: 100%"
          }
        },
        "f2cc1fd0ab6249499c490222a318e773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50eff09b625b4e038a0d90ebe36148c3",
            "max": 1519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1179cae2028a4c7f8c18129f029ced29",
            "value": 1519
          }
        },
        "fdffa29bc86d4e9ea884a75fcfb26db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a6034a4596c43d28969e9d42e486b07",
            "placeholder": "​",
            "style": "IPY_MODEL_15ff9de7541845bdb4245578a2a54a0e",
            "value": " 1.52k/1.52k [00:00&lt;00:00, 50.7kB/s]"
          }
        },
        "5bc1992df4104607bff1f1c3ec1146a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e355427768b4207a8f9b83e1b5a473f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec82981e53bd4d16a3f9a24fa23785d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50eff09b625b4e038a0d90ebe36148c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1179cae2028a4c7f8c18129f029ced29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a6034a4596c43d28969e9d42e486b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ff9de7541845bdb4245578a2a54a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3684561b6364641941959f003e7b65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20dd2c2f44c2456f963f1a5fcaf61ba3",
              "IPY_MODEL_e6f029dcfd054ee0acbb15d533f50744",
              "IPY_MODEL_5b5b3ebbf8a042e0987c1e0fb0c077d2"
            ],
            "layout": "IPY_MODEL_3c77a3b85a3e4090ab107927eba0d468"
          }
        },
        "20dd2c2f44c2456f963f1a5fcaf61ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c8be216e5a74095ac2988c1a78075b0",
            "placeholder": "​",
            "style": "IPY_MODEL_b02c820aea7e41058c71593747a9631a",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "e6f029dcfd054ee0acbb15d533f50744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f00f362fe7e648cdba3cae1eb0aa4920",
            "max": 28090,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f5686e4646040a0b4c5b6b6bb974fa2",
            "value": 28090
          }
        },
        "5b5b3ebbf8a042e0987c1e0fb0c077d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0925d6632047ada10b3459b4239484",
            "placeholder": "​",
            "style": "IPY_MODEL_3a8581daaef64ad4a01bb37c6bceb7ed",
            "value": " 28.1k/28.1k [00:00&lt;00:00, 378kB/s]"
          }
        },
        "3c77a3b85a3e4090ab107927eba0d468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8be216e5a74095ac2988c1a78075b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b02c820aea7e41058c71593747a9631a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f00f362fe7e648cdba3cae1eb0aa4920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5686e4646040a0b4c5b6b6bb974fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c0925d6632047ada10b3459b4239484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8581daaef64ad4a01bb37c6bceb7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e18979f6811546f99384eb533181fa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_624a8fb0e76445ad8139a7fc256c65de",
              "IPY_MODEL_b727eef42b964bfab60bb17431337149",
              "IPY_MODEL_cf6fd985d7034fa9b5bc667508c3d1c7"
            ],
            "layout": "IPY_MODEL_9ba622ba6011477499a4f54db1c35730"
          }
        },
        "624a8fb0e76445ad8139a7fc256c65de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b852090ec0974d8c80ac0a6774ab0dc1",
            "placeholder": "​",
            "style": "IPY_MODEL_6bf74f57670f45e9ac22353e44b14b4a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b727eef42b964bfab60bb17431337149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c25e7e2ee084246ac799428e8a4a556",
            "max": 3061,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10af8299431f452b837b66db60603ebe",
            "value": 3061
          }
        },
        "cf6fd985d7034fa9b5bc667508c3d1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4f3c3e7beed4e6291f56583809e6393",
            "placeholder": "​",
            "style": "IPY_MODEL_7e098cff78f64a1e9634066d46b57068",
            "value": " 3.06k/3.06k [00:00&lt;00:00, 58.9kB/s]"
          }
        },
        "9ba622ba6011477499a4f54db1c35730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b852090ec0974d8c80ac0a6774ab0dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf74f57670f45e9ac22353e44b14b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c25e7e2ee084246ac799428e8a4a556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10af8299431f452b837b66db60603ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4f3c3e7beed4e6291f56583809e6393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e098cff78f64a1e9634066d46b57068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bd3675cf10f47069ad32759fd1287a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24c18eaab5fa4c9b856df8c68bde488c",
              "IPY_MODEL_5d7ed8a9a4594e66b061d567c37d57cd",
              "IPY_MODEL_19de55a35fd043c09648dd9ea17b43c5"
            ],
            "layout": "IPY_MODEL_42ac98ef73a7436e86d9ca2bb09a37ee"
          }
        },
        "24c18eaab5fa4c9b856df8c68bde488c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b2e8c976b14a7599cad900c970df3c",
            "placeholder": "​",
            "style": "IPY_MODEL_980e88328d1a469cb9eec32bd4168f70",
            "value": "tokenizer.json: 100%"
          }
        },
        "5d7ed8a9a4594e66b061d567c37d57cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b259d39194a4c59875ae018bcba0be5",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15c495a82266422487fa0521e52f93f2",
            "value": 7031660
          }
        },
        "19de55a35fd043c09648dd9ea17b43c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce0e8913c1e144a08b854df5157672f6",
            "placeholder": "​",
            "style": "IPY_MODEL_341cf65366274ffe850e171d23b23317",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 21.1MB/s]"
          }
        },
        "42ac98ef73a7436e86d9ca2bb09a37ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b2e8c976b14a7599cad900c970df3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980e88328d1a469cb9eec32bd4168f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b259d39194a4c59875ae018bcba0be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c495a82266422487fa0521e52f93f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce0e8913c1e144a08b854df5157672f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "341cf65366274ffe850e171d23b23317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84a8570ae41642a78495a29930b49247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e662d720b8174d49a7492152324b55c1",
              "IPY_MODEL_339b4882e4274688872b906360521ff7",
              "IPY_MODEL_bd92de3e30c348908d011fdd1f7ad213"
            ],
            "layout": "IPY_MODEL_53916a5de6be4ea990e087e7705553c9"
          }
        },
        "e662d720b8174d49a7492152324b55c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5f2278d15248b99c812423a6a18174",
            "placeholder": "​",
            "style": "IPY_MODEL_b56e5a16fa8342458cc165efb2ca9aa7",
            "value": "q4_k_m.gguf: 100%"
          }
        },
        "339b4882e4274688872b906360521ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d158b4c53964da6bbf74197f40b5085",
            "max": 4290883232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fadeb8dbcdaa41e5a4b6b1c64b76ebcd",
            "value": 4290883232
          }
        },
        "bd92de3e30c348908d011fdd1f7ad213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711ade1c90924b2daf0757c0a149d7e7",
            "placeholder": "​",
            "style": "IPY_MODEL_e331373c31f74a8680e8239b67e6a763",
            "value": " 4.29G/4.29G [02:02&lt;00:00, 35.3MB/s]"
          }
        },
        "53916a5de6be4ea990e087e7705553c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff5f2278d15248b99c812423a6a18174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56e5a16fa8342458cc165efb2ca9aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d158b4c53964da6bbf74197f40b5085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fadeb8dbcdaa41e5a4b6b1c64b76ebcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "711ade1c90924b2daf0757c0a149d7e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e331373c31f74a8680e8239b67e6a763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Cloning the llama.cpp repo and installing dependencies"
      ],
      "metadata": {
        "id": "DsDK_t8nC_Bx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHoBg-ju_d0l",
        "outputId": "dbd81735-fb9d-424f-b7ee-9b9f0732c9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 42763, done.\u001b[K\n",
            "remote: Counting objects: 100% (8049/8049), done.\u001b[K\n",
            "remote: Compressing objects: 100% (416/416), done.\u001b[K\n",
            "remote: Total 42763 (delta 7855), reused 7635 (delta 7633), pack-reused 34714 (from 2)\u001b[K\n",
            "Receiving objects: 100% (42763/42763), 75.64 MiB | 20.53 MiB/s, done.\n",
            "Resolving deltas: 100% (31389/31389), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: sentencepiece~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.45.1 in /usr/local/lib/python3.11/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.47.1)\n",
            "Collecting gguf>=0.1.0 (from -r ./requirements/requirements-convert_legacy_llama.txt (line 4))\n",
            "  Downloading gguf-0.14.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /usr/local/lib/python3.11/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 5)) (4.25.6)\n",
            "Collecting torch~=2.2.1 (from -r ./requirements/requirements-convert_hf_to_gguf.txt (line 3))\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.2%2Bcpu-cp311-cp311-linux_x86_64.whl (186.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.3.0)\n",
            "Downloading gguf-0.14.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gguf, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.2+cpu which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.2+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gguf-0.14.0 torch-2.2.2+cpu\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp.git\n",
        "!cd llama.cpp &&  pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Building llama.cpp locally"
      ],
      "metadata": {
        "id": "X5d_9YhhbMna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd llama.cpp && LLAMA_CUDA=1 && pwd && cmake -B build && cmake --build build --config Release -j$(nproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UJv6wymN453",
        "outputId": "75adc3fb-824c-4414-8f8a-02eac13f9c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llama.cpp\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Configuring done (3.2s)\n",
            "-- Generating done (0.5s)\n",
            "-- Build files have been written to: /content/llama.cpp/build\n",
            "[  0%] \u001b[34m\u001b[1mGenerating build details from Git\u001b[0m\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "[  1%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n",
            "[  1%] Built target build_info\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\u001b[0m\n",
            "[  3%] Built target sha256\n",
            "[  4%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[  4%] Built target xxhash\n",
            "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\u001b[0m\n",
            "[  6%] Built target sha1\n",
            "[  6%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n",
            "[  6%] Built target ggml-base\n",
            "[  7%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n",
            "[ 11%] Built target ggml-cpu\n",
            "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n",
            "[ 12%] Built target ggml\n",
            "[ 13%] \u001b[32mBuilding CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-hash\u001b[0m\n",
            "[ 14%] Built target llama-gguf-hash\n",
            "[ 15%] \u001b[32mBuilding CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf\u001b[0m\n",
            "[ 15%] Built target llama-gguf\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32m\u001b[1mLinking CXX shared library ../bin/libllama.so\u001b[0m\n",
            "[ 24%] Built target llama\n",
            "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding C object tests/CMakeFiles/test-c.dir/test-c.c.o\u001b[0m\n",
            "[ 26%] \u001b[32m\u001b[1mLinking C executable ../bin/test-c\u001b[0m\n",
            "[ 26%] Built target test-c\n",
            "[ 27%] \u001b[32mBuilding CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple\u001b[0m\n",
            "[ 27%] Built target llama-simple\n",
            "[ 28%] \u001b[32mBuilding CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple-chat\u001b[0m\n",
            "[ 28%] Built target llama-simple-chat\n",
            "[ 28%] \u001b[32mBuilding CXX object examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/quantize-stats.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-quantize-stats\u001b[0m\n",
            "[ 29%] Built target llama-quantize-stats\n",
            "[ 29%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llava.dir/llava.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llava.dir/clip.cpp.o\u001b[0m\n",
            "[ 34%] Built target common\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-0\u001b[0m\n",
            "[ 35%] Built target test-tokenizer-0\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-sampling\u001b[0m\n",
            "[ 36%] Built target test-sampling\n",
            "[ 36%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-parser\u001b[0m\n",
            "[ 37%] Built target test-grammar-parser\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-integration\u001b[0m\n",
            "[ 39%] Built target test-grammar-integration\n",
            "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-llama-grammar\u001b[0m\n",
            "[ 40%] Built target test-llama-grammar\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\u001b[0m\n",
            "[ 40%] Built target llava\n",
            "[ 41%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-json-schema-to-grammar\u001b[0m\n",
            "[ 42%] Built target test-json-schema-to-grammar\n",
            "[ 43%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-bpe\u001b[0m\n",
            "[ 43%] Built target test-tokenizer-1-bpe\n",
            "[ 44%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-spm\u001b[0m\n",
            "[ 44%] Built target test-tokenizer-1-spm\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-log\u001b[0m\n",
            "[ 46%] Built target test-log\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-arg-parser\u001b[0m\n",
            "[ 48%] Built target test-arg-parser\n",
            "[ 49%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat\u001b[0m\n",
            "[ 50%] Built target test-chat\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gguf\u001b[0m\n",
            "[ 51%] Built target test-gguf\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat-template\u001b[0m\n",
            "[ 53%] Built target test-chat-template\n",
            "[ 53%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-model-load-cancel\u001b[0m\n",
            "[ 54%] Built target test-model-load-cancel\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-backend-ops\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-autorelease\u001b[0m\n",
            "[ 56%] Built target test-backend-ops\n",
            "[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\u001b[0m\n",
            "[ 56%] Built target test-autorelease\n",
            "[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-barrier\u001b[0m\n",
            "[ 58%] Built target test-barrier\n",
            "[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-fns\u001b[0m\n",
            "[ 59%] Built target test-quantize-fns\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-rope\u001b[0m\n",
            "[ 62%] Built target test-rope\n",
            "[ 63%] \u001b[32mBuilding CXX object examples/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-perf\u001b[0m\n",
            "[ 63%] Built target test-quantize-perf\n",
            "[ 63%] \u001b[32mBuilding CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched-bench\u001b[0m\n",
            "[ 63%] Built target llama-batched-bench\n",
            "[ 64%] \u001b[32mBuilding CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched\u001b[0m\n",
            "[ 64%] Built target llama-batched\n",
            "[ 65%] \u001b[32mBuilding CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-embedding\u001b[0m\n",
            "[ 65%] Built target llama-embedding\n",
            "[ 66%] \u001b[32mBuilding CXX object examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/gbnf-validator.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-eval-callback\u001b[0m\n",
            "[ 66%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gbnf-validator\u001b[0m\n",
            "[ 66%] Built target llama-gbnf-validator\n",
            "[ 67%] \u001b[32mBuilding CXX object examples/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n",
            "[ 67%] Built target llama-eval-callback\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n",
            "[ 68%] Built target llama-gguf-split\n",
            "[ 69%] \u001b[32mBuilding CXX object examples/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gritlm\u001b[0m\n",
            "[ 69%] Built target llama-gritlm\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/infill/CMakeFiles/llama-infill.dir/infill.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-infill\u001b[0m\n",
            "[ 70%] Built target llama-infill\n",
            "[ 71%] \u001b[32mBuilding CXX object examples/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-imatrix\u001b[0m\n",
            "[ 71%] Built target llama-imatrix\n",
            "[ 72%] \u001b[32mBuilding CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookahead\u001b[0m\n",
            "[ 72%] Built target llama-lookahead\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup\u001b[0m\n",
            "[ 73%] Built target llama-lookup\n",
            "[ 74%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-create\u001b[0m\n",
            "[ 74%] Built target llama-lookup-create\n",
            "[ 75%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-merge\u001b[0m\n",
            "[ 75%] Built target llama-lookup-merge\n",
            "[ 76%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-stats\u001b[0m\n",
            "[ 76%] Built target llama-lookup-stats\n",
            "[ 77%] \u001b[32mBuilding CXX object examples/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-bench\u001b[0m\n",
            "[ 77%] Built target llama-bench\n",
            "[ 78%] \u001b[32mBuilding CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-parallel\u001b[0m\n",
            "[ 78%] Built target llama-parallel\n",
            "[ 79%] \u001b[32mBuilding CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-passkey\u001b[0m\n",
            "[ 79%] Built target llama-passkey\n",
            "[ 79%] \u001b[32mBuilding CXX object examples/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cli\u001b[0m\n",
            "[ 79%] Built target llama-cli\n",
            "[ 79%] \u001b[32mBuilding CXX object examples/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-perplexity\u001b[0m\n",
            "[ 80%] Built target llama-perplexity\n",
            "[ 80%] \u001b[32mBuilding CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n",
            "[ 81%] Built target llama-quantize\n",
            "[ 81%] \u001b[34m\u001b[1mGenerating loading.html.hpp\u001b[0m\n",
            "[ 82%] \u001b[34m\u001b[1mGenerating index.html.gz.hpp\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-retrieval\u001b[0m\n",
            "[ 83%] Built target llama-retrieval\n",
            "[ 84%] \u001b[32mBuilding CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object examples/server/CMakeFiles/llama-server.dir/server.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-save-load-state\u001b[0m\n",
            "[ 85%] Built target llama-save-load-state\n",
            "[ 85%] \u001b[32mBuilding CXX object examples/run/CMakeFiles/llama-run.dir/run.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object examples/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-run\u001b[0m\n",
            "[ 86%] Built target llama-run\n",
            "[ 87%] \u001b[32mBuilding CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative\u001b[0m\n",
            "[ 87%] Built target llama-speculative\n",
            "[ 88%] \u001b[32mBuilding CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative-simple\u001b[0m\n",
            "[ 88%] Built target llama-speculative-simple\n",
            "[ 89%] \u001b[32mBuilding CXX object examples/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tokenize\u001b[0m\n",
            "[ 89%] Built target llama-tokenize\n",
            "[ 90%] \u001b[32mBuilding CXX object examples/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tts\u001b[0m\n",
            "[ 90%] Built target llama-tts\n",
            "[ 91%] \u001b[32mBuilding CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gen-docs\u001b[0m\n",
            "[ 91%] Built target llama-gen-docs\n",
            "[ 92%] \u001b[32mBuilding CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-convert-llama2c-to-ggml\u001b[0m\n",
            "[ 92%] Built target llama-convert-llama2c-to-ggml\n",
            "[ 93%] \u001b[32mBuilding CXX object examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cvector-generator\u001b[0m\n",
            "[ 93%] Built target llama-cvector-generator\n",
            "[ 94%] \u001b[32mBuilding CXX object examples/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-export-lora\u001b[0m\n",
            "[ 94%] Built target llama-export-lora\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX static library libllava_static.a\u001b[0m\n",
            "[ 94%] Built target llava_static\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libllava_shared.so\u001b[0m\n",
            "[ 95%] Built target llava_shared\n",
            "[ 96%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-llava-cli.dir/llava-cli.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-server\u001b[0m\n",
            "[ 96%] Built target llama-server\n",
            "[ 97%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-minicpmv-cli.dir/minicpmv-cli.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-llava-cli\u001b[0m\n",
            "[ 97%] Built target llama-llava-cli\n",
            "[ 97%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/qwen2vl-cli.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-minicpmv-cli\u001b[0m\n",
            "[ 97%] Built target llama-minicpmv-cli\n",
            "[ 98%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-vdot\u001b[0m\n",
            "[ 98%] Built target llama-vdot\n",
            "[ 98%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-qwen2vl-cli\u001b[0m\n",
            "[ 99%] Built target llama-qwen2vl-cli\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-q8dot\u001b[0m\n",
            "[100%] Built target llama-q8dot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Downloading deepseek model from hugging face official repo"
      ],
      "metadata": {
        "id": "8P8FuztTce_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "original_model= \"./original_model/\"\n",
        "snapshot_download(repo_id=model_id, local_dir=original_model,local_dir_use_symlinks=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "11b0842181834b3ab8496d12cd863824",
            "1655ce86979844398ac438bb15abe9a9",
            "02d794b025ef4fc2816fbf3afa89f87c",
            "c03b3255f38b493eb2c4a19893af9fd9",
            "b9127b7e08274117b0933a6b20b9663d",
            "b27d4ec2ab2d4ae5beb30ef0933c7c62",
            "dcf44bfbf3df4800aa985fa6356d9a50",
            "f6e68902f07c4e3cb8692322c2f011af",
            "3021d57b411549cc91a694921f6b54ce",
            "e2c41106deea4dcf90ce4f435ae40486",
            "06c64f02b7d5432b82c314c10e67c3b9",
            "9177fb7fa09e491dbf6a7b88ecf78380",
            "0e13925b4018441595defa5ce79090ab",
            "cf8ac975033b4611b06d6fec2128123a",
            "f34ade792e6b45e2a4382abcbd061640",
            "08b57f774af54e03ad6808954f12da8b",
            "9262e4a304544dbd91e7e032f53ca987",
            "bdd982dbae3b438a85e700c2b212ab80",
            "1796d44851d848cfaf5905c502e32259",
            "ab1cc2b16f384d79906efc589f76c9b6",
            "8b00109ab1fe425fa63935d89ffc1feb",
            "7f30cf9da16a43b187505db214ae4022",
            "1e110699fc064bfc88ba50ae52fadb6f",
            "8477e1656abc439cb121354e7a1cba45",
            "be84522b7fc3401fa35e7d722d0935f9",
            "aea5c90397c345ceb5e8c82287a0fb4b",
            "2a03ba4bc8b84a7bbfd646bf771e52c2",
            "78eeb3b438444cec8cf015ab2d15fade",
            "92cfa354497f483eae05e372eff6ced3",
            "97dcd3842d7f415790b0b279828950e1",
            "684db16cc44540ec8146a3a30434ec7d",
            "fac11a98994644ec87e4e36f1f1752c6",
            "93aad35ba2d14a48838834e8e9d665dc",
            "3d1d5434caa14d4cbfa1373846a4ec95",
            "1a17c2c0461f447c9d56a8f08e2722c6",
            "7520be07cc9e447793a7ae994f906fed",
            "e28dd782f98949d5a9ed037f74e9f08f",
            "0eece40ab32b4823b47c641183a7b548",
            "eb486d80c2964438aaa154a01646ce40",
            "202d791ee992434294fbe802d0d56381",
            "25cb29d946ba40abbf786c06e699a577",
            "2337cc618d0f4a4688dfe74ebc9e57d2",
            "1768bf2af040497a91a7fe7a02d865c9",
            "3e3c5c28949d46efaeec0698bd33908a",
            "5a0c80c95e55444b8b43dc75da10c9f1",
            "a2e6f1a7a11f4502a4856959c403bea3",
            "be735e2ac5b5468f9a6ca68fb2bd99f9",
            "178b351a72414c47b03e94de518e99a0",
            "0f91772c8bf643e497f6ec05a7451625",
            "ee9c79ff95f04e68a014deef73a63568",
            "263bff5d4b1c48ec97f68bd01727fcd6",
            "c80e6ca7349540f184dfb1ab2a7d197a",
            "3630862d14c6467d996a366a7474d9a5",
            "cace4eac382143bcb7ded71ed02e2ba9",
            "8e4054b8bf4847c5bfc5b84f449dfac5",
            "dd9d0c40c4c241f8a71bb1d5e5ce10d1",
            "f7502a55901142c99afd650319680161",
            "d315daf872134d1199737631020f05a4",
            "e9591eeec09546fea91854a075c47963",
            "6e2b8fc2203a438ab874052490673d6c",
            "fc92985363da4862a411cdc1bd8b70fb",
            "45f14abc491b4d8a8842a41c22ff89cd",
            "a3cca5ab55364564a076e0113e41bd73",
            "e9b43c331e604bf09598eb2dcb061607",
            "8cda426830dc4c6390bd3a33bc1a3fb0",
            "e39079c3f5da41e5b5909aef438b5e99",
            "ad169cdf838c42adacd1d1271da7e8f2",
            "e988087f813d49529b7314eb8bba80dc",
            "64bbe3cab6aa44d4a89cd381f49b360a",
            "6b4fb3dee8b846fab8aa063ede7d1a5b",
            "13404d8367764b1cb0df9281ddb4c2c3",
            "e656e57b505b409abc43b554e8c3fb33",
            "385fd67104d14e24aab3a421c90ae57d",
            "8bbd47a5b15f44c79c27f3900e8503eb",
            "7e1c029908c6406cb61ad112efd7b9ec",
            "3c85e2eacff84e9d9253aac350c8337a",
            "2705fb0b5434480a9cefe00dce0b8280",
            "6a57cfcad70f45ee8da99a124560d0b0",
            "7f44e75f42f74ca9861c5b4e42a99199",
            "6f0756455e8044f4a1ae045839790da6",
            "811cf9087f48476d9d781a630e071ac2",
            "9de941cd4c9643dbae0cd6e0be93176d",
            "909d9da289d04b9dbbf7f5b181143bbe",
            "3d2c104a772d4fc99781f64ef1b3a72e",
            "c414afcc3de6491a8ddb6c737ad168ff",
            "de24194fe7684bd4bbd62b0aee3f86c3",
            "30d58907d2a94dfc8843208c238dbd64",
            "b809942fc4a84914b0f68f14d2be4ad4",
            "8f9a42ec9bee47a4ac36a95036793fd9",
            "7d783448568647a6ad7123cd2c61e339",
            "f2cc1fd0ab6249499c490222a318e773",
            "fdffa29bc86d4e9ea884a75fcfb26db4",
            "5bc1992df4104607bff1f1c3ec1146a6",
            "9e355427768b4207a8f9b83e1b5a473f",
            "ec82981e53bd4d16a3f9a24fa23785d0",
            "50eff09b625b4e038a0d90ebe36148c3",
            "1179cae2028a4c7f8c18129f029ced29",
            "2a6034a4596c43d28969e9d42e486b07",
            "15ff9de7541845bdb4245578a2a54a0e",
            "b3684561b6364641941959f003e7b65a",
            "20dd2c2f44c2456f963f1a5fcaf61ba3",
            "e6f029dcfd054ee0acbb15d533f50744",
            "5b5b3ebbf8a042e0987c1e0fb0c077d2",
            "3c77a3b85a3e4090ab107927eba0d468",
            "6c8be216e5a74095ac2988c1a78075b0",
            "b02c820aea7e41058c71593747a9631a",
            "f00f362fe7e648cdba3cae1eb0aa4920",
            "4f5686e4646040a0b4c5b6b6bb974fa2",
            "3c0925d6632047ada10b3459b4239484",
            "3a8581daaef64ad4a01bb37c6bceb7ed",
            "e18979f6811546f99384eb533181fa41",
            "624a8fb0e76445ad8139a7fc256c65de",
            "b727eef42b964bfab60bb17431337149",
            "cf6fd985d7034fa9b5bc667508c3d1c7",
            "9ba622ba6011477499a4f54db1c35730",
            "b852090ec0974d8c80ac0a6774ab0dc1",
            "6bf74f57670f45e9ac22353e44b14b4a",
            "7c25e7e2ee084246ac799428e8a4a556",
            "10af8299431f452b837b66db60603ebe",
            "f4f3c3e7beed4e6291f56583809e6393",
            "7e098cff78f64a1e9634066d46b57068",
            "9bd3675cf10f47069ad32759fd1287a6",
            "24c18eaab5fa4c9b856df8c68bde488c",
            "5d7ed8a9a4594e66b061d567c37d57cd",
            "19de55a35fd043c09648dd9ea17b43c5",
            "42ac98ef73a7436e86d9ca2bb09a37ee",
            "96b2e8c976b14a7599cad900c970df3c",
            "980e88328d1a469cb9eec32bd4168f70",
            "6b259d39194a4c59875ae018bcba0be5",
            "15c495a82266422487fa0521e52f93f2",
            "ce0e8913c1e144a08b854df5157672f6",
            "341cf65366274ffe850e171d23b23317"
          ]
        },
        "id": "dGUsmcnLDSpg",
        "outputId": "02212093-6dbf-4f2e-fa07-f45410f07d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:832: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11b0842181834b3ab8496d12cd863824"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9177fb7fa09e491dbf6a7b88ecf78380"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/18.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e110699fc064bfc88ba50ae52fadb6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LICENSE:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d1d5434caa14d4cbfa1373846a4ec95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "figures/benchmark.jpg:   0%|          | 0.00/777k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a0c80c95e55444b8b43dc75da10c9f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd9d0c40c4c241f8a71bb1d5e5ce10d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad169cdf838c42adacd1d1271da7e8f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-000002.safetensors:   0%|          | 0.00/6.62G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a57cfcad70f45ee8da99a124560d0b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f9a42ec9bee47a4ac36a95036793fd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3684561b6364641941959f003e7b65a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e18979f6811546f99384eb533181fa41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bd3675cf10f47069ad32759fd1287a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/original_model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./llama.cpp/build/bin/llama-cli --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Dw_Yes4dNG",
        "outputId": "2c8d81f1-8984-4018-9db1-3bc5f23f8fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "version: 4607 (aa6fb132)\n",
            "built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Converting tensors from hf to .gguf format for quantization"
      ],
      "metadata": {
        "id": "Srms8jj-deyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./quantized_model/\n",
        "!python llama.cpp/convert_hf_to_gguf.py ./original_model --outtype f16 --outfile ./quantized_model/FP16.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRMHTko6DvfW",
        "outputId": "3b07b1f8-01a5-47e6-ac4a-f32a41fb0682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:hf-to-gguf:Loading model: original_model\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-000002.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,         torch.bfloat16 --> F16, shape = {3584, 152064}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.bias,         torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.bias,         torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-000002.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,             torch.bfloat16 --> F16, shape = {3584, 152064}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,   torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,    torch.bfloat16 --> F16, shape = {18944, 3584}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,    torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,      torch.bfloat16 --> F16, shape = {3584, 18944}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight, torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.bias,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,      torch.bfloat16 --> F16, shape = {3584, 3584}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.bias,        torch.bfloat16 --> F32, shape = {512}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,      torch.bfloat16 --> F16, shape = {3584, 512}\n",
            "INFO:hf-to-gguf:output_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 131072\n",
            "INFO:hf-to-gguf:gguf: embedding length = 3584\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 18944\n",
            "INFO:hf-to-gguf:gguf: head count = 28\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 4\n",
            "INFO:hf-to-gguf:gguf: rope theta = 10000\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "2025-01-31 19:41:54.617290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738352514.806935    8022 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738352514.859950    8022 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-31 19:41:55.261867: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO:gguf.vocab:Adding 151387 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 151646\n",
            "INFO:gguf.vocab:Setting special token type eos to 151643\n",
            "INFO:gguf.vocab:Setting special token type pad to 151643\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:quantized_model/FP16.gguf: n_tensors = 339, total_size = 15.2G\n",
            "Writing: 100% 15.2G/15.2G [03:14<00:00, 78.1Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to quantized_model/FP16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Quantising the model"
      ],
      "metadata": {
        "id": "-yj1RNX51cUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "methods = [\"q4_k_m\"]\n",
        "quantized_path = \"./quantized_model/\"\n",
        "\n",
        "for m in methods:\n",
        "    qtype = f\"{quantized_path}/{m.upper()}.gguf\"\n",
        "    os.system(\"./llama.cpp/quantize \"+quantized_path+\"/FP16.gguf \"+qtype+\" \"+m)"
      ],
      "metadata": {
        "id": "0a5N8vLyD9yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./llama.cpp/build/bin/llama-quantize --pure /content/quantized_model/FP16.gguf /content/quantized_model/q4_k_m.gguf Q4_K_M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XICIXD3CYyv3",
        "outputId": "0750163f-385e-4c5d-d9d9-edff52db21e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main: build = 4607 (aa6fb132)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/quantized_model/FP16.gguf' to '/content/quantized_model/q4_k_m.gguf' as Q4_K_M\n",
            "llama_model_loader: loaded meta data with 26 key-value pairs and 339 tensors from /content/quantized_model/FP16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Original_Model\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 7.6B\n",
            "llama_model_loader: - kv   4:                            general.license str              = mit\n",
            "llama_model_loader: - kv   5:                          qwen2.block_count u32              = 28\n",
            "llama_model_loader: - kv   6:                       qwen2.context_length u32              = 131072\n",
            "llama_model_loader: - kv   7:                     qwen2.embedding_length u32              = 3584\n",
            "llama_model_loader: - kv   8:                  qwen2.feed_forward_length u32              = 18944\n",
            "llama_model_loader: - kv   9:                 qwen2.attention.head_count u32              = 28\n",
            "llama_model_loader: - kv  10:              qwen2.attention.head_count_kv u32              = 4\n",
            "llama_model_loader: - kv  11:                       qwen2.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  12:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  13:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  15:                         tokenizer.ggml.pre str              = deepseek-r1-qwen\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,152064]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,152064]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  18:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 151646\n",
            "llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151643\n",
            "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
            "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  141 tensors\n",
            "llama_model_loader: - type  f16:  198 tensors\n",
            "[   1/ 339]                        output.weight - [ 3584, 152064,     1,     1], type =    f16, converting to q4_K .. size =  1039.50 MiB ->   292.36 MiB\n",
            "[   2/ 339]                   output_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[   3/ 339]                    token_embd.weight - [ 3584, 152064,     1,     1], type =    f16, converting to q4_K .. size =  1039.50 MiB ->   292.36 MiB\n",
            "[   4/ 339]                    blk.0.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[   5/ 339]                  blk.0.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[   6/ 339]               blk.0.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[   7/ 339]             blk.0.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[   8/ 339]                    blk.0.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[   9/ 339]                  blk.0.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  10/ 339]                    blk.0.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  11/ 339]                  blk.0.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  12/ 339]                blk.0.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  13/ 339]                blk.0.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  14/ 339]                blk.0.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  15/ 339]                  blk.0.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  16/ 339]                    blk.1.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  17/ 339]                  blk.1.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  18/ 339]               blk.1.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  19/ 339]             blk.1.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  20/ 339]                    blk.1.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  21/ 339]                  blk.1.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  22/ 339]                    blk.1.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  23/ 339]                  blk.1.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  24/ 339]                blk.1.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  25/ 339]                blk.1.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  26/ 339]                blk.1.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  27/ 339]                  blk.1.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  28/ 339]                    blk.2.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  29/ 339]                  blk.2.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  30/ 339]               blk.2.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  31/ 339]             blk.2.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  32/ 339]                    blk.2.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  33/ 339]                  blk.2.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  34/ 339]                    blk.2.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  35/ 339]                  blk.2.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  36/ 339]                blk.2.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  37/ 339]                blk.2.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  38/ 339]                blk.2.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  39/ 339]                  blk.2.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  40/ 339]                    blk.3.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  41/ 339]                  blk.3.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  42/ 339]               blk.3.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  43/ 339]             blk.3.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  44/ 339]                    blk.3.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  45/ 339]                  blk.3.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  46/ 339]                    blk.3.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  47/ 339]                  blk.3.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  48/ 339]                blk.3.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  49/ 339]                blk.3.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  50/ 339]                blk.3.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  51/ 339]                  blk.3.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  52/ 339]                    blk.4.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  53/ 339]                  blk.4.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  54/ 339]               blk.4.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  55/ 339]             blk.4.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  56/ 339]                    blk.4.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  57/ 339]                  blk.4.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  58/ 339]                    blk.4.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  59/ 339]                  blk.4.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  60/ 339]                blk.4.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  61/ 339]                blk.4.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  62/ 339]                blk.4.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  63/ 339]                  blk.4.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  64/ 339]                    blk.5.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  65/ 339]                  blk.5.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  66/ 339]               blk.5.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  67/ 339]             blk.5.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  68/ 339]                    blk.5.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  69/ 339]                  blk.5.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  70/ 339]                    blk.5.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  71/ 339]                  blk.5.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  72/ 339]                blk.5.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  73/ 339]                blk.5.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  74/ 339]                blk.5.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  75/ 339]                  blk.5.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  76/ 339]                    blk.6.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  77/ 339]                  blk.6.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  78/ 339]               blk.6.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  79/ 339]             blk.6.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  80/ 339]                    blk.6.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  81/ 339]                  blk.6.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  82/ 339]                    blk.6.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  83/ 339]                  blk.6.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  84/ 339]                blk.6.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  85/ 339]                blk.6.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  86/ 339]                blk.6.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  87/ 339]                  blk.6.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  88/ 339]                    blk.7.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  89/ 339]                  blk.7.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  90/ 339]               blk.7.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  91/ 339]             blk.7.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  92/ 339]                    blk.7.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  93/ 339]                  blk.7.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[  94/ 339]                    blk.7.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[  95/ 339]                  blk.7.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[  96/ 339]                blk.7.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  97/ 339]                blk.7.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[  98/ 339]                blk.7.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[  99/ 339]                  blk.7.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 100/ 339]                    blk.8.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 101/ 339]                  blk.8.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 102/ 339]               blk.8.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 103/ 339]             blk.8.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 104/ 339]                    blk.8.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 105/ 339]                  blk.8.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 106/ 339]                    blk.8.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 107/ 339]                  blk.8.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 108/ 339]                blk.8.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 109/ 339]                blk.8.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 110/ 339]                blk.8.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 111/ 339]                  blk.8.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 112/ 339]                    blk.9.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 113/ 339]                  blk.9.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 114/ 339]               blk.9.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 115/ 339]             blk.9.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 116/ 339]                    blk.9.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 117/ 339]                  blk.9.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 118/ 339]                    blk.9.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 119/ 339]                  blk.9.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 120/ 339]                blk.9.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 121/ 339]                blk.9.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 122/ 339]                blk.9.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 123/ 339]                  blk.9.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 124/ 339]                   blk.10.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 125/ 339]                 blk.10.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 126/ 339]              blk.10.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 127/ 339]            blk.10.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 128/ 339]                   blk.10.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 129/ 339]                 blk.10.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 130/ 339]                   blk.10.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 131/ 339]                 blk.10.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 132/ 339]               blk.10.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 133/ 339]               blk.10.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 134/ 339]               blk.10.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 135/ 339]                 blk.10.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 136/ 339]                   blk.11.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 137/ 339]                 blk.11.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 138/ 339]              blk.11.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 139/ 339]            blk.11.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 140/ 339]                   blk.11.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 141/ 339]                 blk.11.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 142/ 339]                   blk.11.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 143/ 339]                 blk.11.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 144/ 339]               blk.11.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 145/ 339]               blk.11.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 146/ 339]               blk.11.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 147/ 339]                 blk.11.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 148/ 339]                   blk.12.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 149/ 339]                 blk.12.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 150/ 339]              blk.12.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 151/ 339]            blk.12.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 152/ 339]                   blk.12.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 153/ 339]                 blk.12.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 154/ 339]                   blk.12.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 155/ 339]                 blk.12.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 156/ 339]               blk.12.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 157/ 339]               blk.12.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 158/ 339]               blk.12.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 159/ 339]                 blk.12.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 160/ 339]                   blk.13.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 161/ 339]                 blk.13.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 162/ 339]              blk.13.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 163/ 339]            blk.13.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 164/ 339]                   blk.13.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 165/ 339]                 blk.13.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 166/ 339]                   blk.13.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 167/ 339]                 blk.13.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 168/ 339]               blk.13.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 169/ 339]               blk.13.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 170/ 339]               blk.13.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 171/ 339]                 blk.13.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 172/ 339]                   blk.14.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 173/ 339]                 blk.14.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 174/ 339]              blk.14.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 175/ 339]            blk.14.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 176/ 339]                   blk.14.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 177/ 339]                 blk.14.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 178/ 339]                   blk.14.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 179/ 339]                 blk.14.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 180/ 339]               blk.14.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 181/ 339]               blk.14.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 182/ 339]               blk.14.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 183/ 339]                 blk.14.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 184/ 339]                   blk.15.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 185/ 339]                 blk.15.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 186/ 339]              blk.15.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 187/ 339]            blk.15.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 188/ 339]                   blk.15.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 189/ 339]                 blk.15.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 190/ 339]                   blk.15.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 191/ 339]                 blk.15.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 192/ 339]               blk.15.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 193/ 339]               blk.15.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 194/ 339]               blk.15.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 195/ 339]                 blk.15.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 196/ 339]                   blk.16.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 197/ 339]                 blk.16.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 198/ 339]              blk.16.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 199/ 339]            blk.16.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 200/ 339]                   blk.16.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 201/ 339]                 blk.16.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 202/ 339]                   blk.16.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 203/ 339]                 blk.16.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 204/ 339]               blk.16.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 205/ 339]               blk.16.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 206/ 339]               blk.16.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 207/ 339]                 blk.16.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 208/ 339]                   blk.17.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 209/ 339]                 blk.17.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 210/ 339]              blk.17.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 211/ 339]            blk.17.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 212/ 339]                   blk.17.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 213/ 339]                 blk.17.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 214/ 339]                   blk.17.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 215/ 339]                 blk.17.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 216/ 339]               blk.17.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 217/ 339]               blk.17.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 218/ 339]               blk.17.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 219/ 339]                 blk.17.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 220/ 339]                   blk.18.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 221/ 339]                 blk.18.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 222/ 339]              blk.18.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 223/ 339]            blk.18.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 224/ 339]                   blk.18.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 225/ 339]                 blk.18.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 226/ 339]                   blk.18.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 227/ 339]                 blk.18.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 228/ 339]               blk.18.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 229/ 339]               blk.18.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 230/ 339]               blk.18.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 231/ 339]                 blk.18.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 232/ 339]                   blk.19.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 233/ 339]                 blk.19.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 234/ 339]              blk.19.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 235/ 339]            blk.19.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 236/ 339]                   blk.19.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 237/ 339]                 blk.19.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 238/ 339]                   blk.19.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 239/ 339]                 blk.19.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 240/ 339]               blk.19.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 241/ 339]               blk.19.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 242/ 339]               blk.19.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 243/ 339]                 blk.19.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 244/ 339]                   blk.20.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 245/ 339]                 blk.20.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 246/ 339]              blk.20.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 247/ 339]            blk.20.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 248/ 339]                   blk.20.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 249/ 339]                 blk.20.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 250/ 339]                   blk.20.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 251/ 339]                 blk.20.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 252/ 339]               blk.20.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 253/ 339]               blk.20.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 254/ 339]               blk.20.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 255/ 339]                 blk.20.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 256/ 339]                   blk.21.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 257/ 339]                 blk.21.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 258/ 339]              blk.21.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 259/ 339]            blk.21.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 260/ 339]                   blk.21.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 261/ 339]                 blk.21.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 262/ 339]                   blk.21.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 263/ 339]                 blk.21.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 264/ 339]               blk.21.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 265/ 339]               blk.21.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 266/ 339]               blk.21.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 267/ 339]                 blk.21.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 268/ 339]                   blk.22.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 269/ 339]                 blk.22.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 270/ 339]              blk.22.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 271/ 339]            blk.22.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 272/ 339]                   blk.22.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 273/ 339]                 blk.22.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 274/ 339]                   blk.22.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 275/ 339]                 blk.22.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 276/ 339]               blk.22.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 277/ 339]               blk.22.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 278/ 339]               blk.22.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 279/ 339]                 blk.22.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 280/ 339]                   blk.23.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 281/ 339]                 blk.23.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 282/ 339]              blk.23.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 283/ 339]            blk.23.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 284/ 339]                   blk.23.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 285/ 339]                 blk.23.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 286/ 339]                   blk.23.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 287/ 339]                 blk.23.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 288/ 339]               blk.23.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 289/ 339]               blk.23.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 290/ 339]               blk.23.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 291/ 339]                 blk.23.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 292/ 339]                   blk.24.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 293/ 339]                 blk.24.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 294/ 339]              blk.24.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 295/ 339]            blk.24.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 296/ 339]                   blk.24.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 297/ 339]                 blk.24.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 298/ 339]                   blk.24.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 299/ 339]                 blk.24.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 300/ 339]               blk.24.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 301/ 339]               blk.24.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 302/ 339]               blk.24.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 303/ 339]                 blk.24.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 304/ 339]                   blk.25.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 305/ 339]                 blk.25.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 306/ 339]              blk.25.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 307/ 339]            blk.25.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 308/ 339]                   blk.25.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 309/ 339]                 blk.25.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 310/ 339]                   blk.25.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 311/ 339]                 blk.25.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 312/ 339]               blk.25.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 313/ 339]               blk.25.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 314/ 339]               blk.25.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 315/ 339]                 blk.25.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 316/ 339]                   blk.26.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 317/ 339]                 blk.26.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 318/ 339]              blk.26.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 319/ 339]            blk.26.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 320/ 339]                   blk.26.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 321/ 339]                 blk.26.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 322/ 339]                   blk.26.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 323/ 339]                 blk.26.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 324/ 339]               blk.26.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 325/ 339]               blk.26.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 326/ 339]               blk.26.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 327/ 339]                 blk.26.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 328/ 339]                   blk.27.attn_k.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 329/ 339]                 blk.27.attn_k.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 330/ 339]              blk.27.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 331/ 339]            blk.27.attn_output.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 332/ 339]                   blk.27.attn_q.bias - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 333/ 339]                 blk.27.attn_q.weight - [ 3584,  3584,     1,     1], type =    f16, converting to q4_K .. size =    24.50 MiB ->     6.89 MiB\n",
            "[ 334/ 339]                   blk.27.attn_v.bias - [  512,     1,     1,     1], type =    f32, size =    0.002 MB\n",
            "[ 335/ 339]                 blk.27.attn_v.weight - [ 3584,   512,     1,     1], type =    f16, converting to q4_K .. size =     3.50 MiB ->     0.98 MiB\n",
            "[ 336/ 339]               blk.27.ffn_down.weight - [18944,  3584,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 337/ 339]               blk.27.ffn_gate.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "[ 338/ 339]               blk.27.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
            "[ 339/ 339]                 blk.27.ffn_up.weight - [ 3584, 18944,     1,     1], type =    f16, converting to q4_K .. size =   129.50 MiB ->    36.42 MiB\n",
            "llama_model_quantize_impl: model size  = 14526.27 MB\n",
            "llama_model_quantize_impl: quant size  =  4086.43 MB\n",
            "\n",
            "main: quantize time = 1025031.90 ms\n",
            "main:    total time = 1025031.90 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking the quantised model"
      ],
      "metadata": {
        "id": "AgpTImJ11gnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ./llama.cpp/build/bin/llama-cli -m /content/quantized_model/q4_k_m.gguf  -n 90 --repeat_penalty 1.0 --color -i -r \"User:\" -f llama.cpp/prompts/reason-act.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEy_owtnsfRR",
        "outputId": "6baf05f5-409f-4ee6-b2a7-5afeadac32a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build: 4607 (aa6fb132) with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: llama backend init\n",
            "main: load the model and apply lora adapter, if any\n",
            "llama_model_loader: loaded meta data with 26 key-value pairs and 339 tensors from /content/quantized_model/q4_k_m.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Original_Model\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 7.6B\n",
            "llama_model_loader: - kv   4:                            general.license str              = mit\n",
            "llama_model_loader: - kv   5:                          qwen2.block_count u32              = 28\n",
            "llama_model_loader: - kv   6:                       qwen2.context_length u32              = 131072\n",
            "llama_model_loader: - kv   7:                     qwen2.embedding_length u32              = 3584\n",
            "llama_model_loader: - kv   8:                  qwen2.feed_forward_length u32              = 18944\n",
            "llama_model_loader: - kv   9:                 qwen2.attention.head_count u32              = 28\n",
            "llama_model_loader: - kv  10:              qwen2.attention.head_count_kv u32              = 4\n",
            "llama_model_loader: - kv  11:                       qwen2.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  12:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = deepseek-r1-qwen\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,152064]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,152064]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 151646\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 151643\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 151643\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
            "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  25:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:  141 tensors\n",
            "llama_model_loader: - type q4_K:  198 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 3.99 GiB (4.50 BPW) \n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 22\n",
            "load: token to piece cache size = 0.9310 MB\n",
            "print_info: arch             = qwen2\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 3584\n",
            "print_info: n_layer          = 28\n",
            "print_info: n_head           = 28\n",
            "print_info: n_head_kv        = 4\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 7\n",
            "print_info: n_embd_k_gqa     = 512\n",
            "print_info: n_embd_v_gqa     = 512\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-06\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: n_ff             = 18944\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 131072\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 7.62 B\n",
            "print_info: general.name     = Original_Model\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 152064\n",
            "print_info: n_merges         = 151387\n",
            "print_info: BOS token        = 151646 '<｜begin▁of▁sentence｜>'\n",
            "print_info: EOS token        = 151643 '<｜end▁of▁sentence｜>'\n",
            "print_info: EOT token        = 151643 '<｜end▁of▁sentence｜>'\n",
            "print_info: PAD token        = 151643 '<｜end▁of▁sentence｜>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
            "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
            "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
            "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
            "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
            "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
            "print_info: EOG token        = 151643 '<｜end▁of▁sentence｜>'\n",
            "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
            "print_info: EOG token        = 151663 '<|repo_name|>'\n",
            "print_info: EOG token        = 151664 '<|file_sep|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors:   CPU_Mapped model buffer size =  4086.43 MiB\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 4096\n",
            "llama_init_from_model: n_ctx_per_seq = 4096\n",
            "llama_init_from_model: n_batch       = 2048\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 10000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   224.00 MiB\n",
            "llama_init_from_model: KV self size  =  224.00 MiB, K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.58 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =   304.00 MiB\n",
            "llama_init_from_model: graph nodes  = 986\n",
            "llama_init_from_model: graph splits = 1\n",
            "common_init_from_params: setting dry_penalty_last_n to ctx_size = 4096\n",
            "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
            "main: llama threadpool init, n_threads = 1\n",
            "main: chat template is available, enabling conversation mode (disable it with -no-cnv)\n",
            "main: chat template example:\n",
            "You are a helpful assistant\n",
            "\n",
            "<｜User｜>Hello<｜Assistant｜>Hi there<｜end▁of▁sentence｜><｜User｜>How are you?<｜Assistant｜>\n",
            "\n",
            "system_info: n_threads = 1 (n_threads_batch = 1) / 2 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "\n",
            "main: interactive mode on.\n",
            "Reverse prompt: 'User:'\n",
            "sampler seed: 2915549353\n",
            "sampler params: \n",
            "\trepeat_last_n = 64, repeat_penalty = 1.000, frequency_penalty = 0.000, presence_penalty = 0.000\n",
            "\tdry_multiplier = 0.000, dry_base = 1.750, dry_allowed_length = 2, dry_penalty_last_n = 4096\n",
            "\ttop_k = 40, top_p = 0.950, min_p = 0.050, xtc_probability = 0.000, xtc_threshold = 0.100, typical_p = 1.000, temp = 0.800\n",
            "\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n",
            "sampler chain: logits -> logit-bias -> penalties -> dry -> top-k -> typical -> top-p -> min-p -> xtc -> temp-ext -> dist \n",
            "generate: n_ctx = 4096, n_batch = 2048, n_predict = 90, n_keep = 1\n",
            "\n",
            "\u001b[33m== Running in interactive mode. ==\n",
            " - Press Ctrl+C to interject at any time.\n",
            " - Press Return to return control to the AI.\n",
            " - To return control without starting a new line, end your input with '/'.\n",
            " - If you want to submit another line, end your input with '\\'.\n",
            "\n",
            "You run in a loop of Thought, Action, Observation.\n",
            "At the end of the loop either Answer or restate your Thought and Action.\n",
            "Use Thought to\u001b[0m describe your thoughts about the question you have been asked.\n",
            "Use Action to run one of these actions available to you:\n",
            "- calculate[python math expression]\n",
            "Observation will be the result of running those actions\n",
            "\n",
            "\n",
            "Question: What is 4 * 7 / 3?\n",
            "Thought: Do I need to use an action? Yes, I use calculate to do math\n",
            "Action: calculate[4 * 7 / 3]\n",
            "Observation: 9.3333333333\n",
            "Thought: Do I need to use an action? No, have the result\n",
            "Answer: The calculate tool says it is 9.3333333333\n",
            "Question: What is capital of france?\n",
            "Thought: Do I need to use an action? No, I know the answer\n",
            "Answer: Paris is the capital of France\n",
            "Question:\n",
            "\n",
            "\u001b[1m\u001b[32m\n",
            "> how many states are there in india\n",
            "\u001b[0m<think>\n",
            "Okay, so I need to figure out how many states are there in India. Hmm, I'm not exactly sure, but I think it's a bit more than 29. Wait, wasn't it around 50 before some were split off? Let me try to recall. I remember learning that India used to have a system where states were divided into regions\n",
            "llama_perf_sampler_print:    sampling time =      15.85 ms /    87 runs   (    0.18 ms per token,  5490.34 tokens per second)\n",
            "llama_perf_context_print:        load time =   17768.43 ms\n",
            "llama_perf_context_print: prompt eval time =   91161.75 ms /   219 tokens (  416.26 ms per token,     2.40 tokens per second)\n",
            "llama_perf_context_print:        eval time =   50101.65 ms /    75 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
            "llama_perf_context_print:       total time =  141704.94 ms /   294 tokens\n",
            "Interrupted by user\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Uploading to hugging face"
      ],
      "metadata": {
        "id": "jIXHkrof1led"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "J_ZBJmNxkk4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, upload_file\n",
        "\n",
        "\n",
        "login(os.environ[\"HF_TOKEN\"])\n",
        "\n",
        "\n",
        "model_path = \"./quantized_model/q4_k_m.gguf\"\n",
        "repo_id = \"Rewatiramans/DeepSeek-R1-Distill-Qwen-7B-Q4-GGUF\"\n",
        "\n",
        "\n",
        "upload_file(\n",
        "    path_or_fileobj=model_path,\n",
        "    path_in_repo=\"Q4_K_M.gguf\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "84a8570ae41642a78495a29930b49247",
            "e662d720b8174d49a7492152324b55c1",
            "339b4882e4274688872b906360521ff7",
            "bd92de3e30c348908d011fdd1f7ad213",
            "53916a5de6be4ea990e087e7705553c9",
            "ff5f2278d15248b99c812423a6a18174",
            "b56e5a16fa8342458cc165efb2ca9aa7",
            "6d158b4c53964da6bbf74197f40b5085",
            "fadeb8dbcdaa41e5a4b6b1c64b76ebcd",
            "711ade1c90924b2daf0757c0a149d7e7",
            "e331373c31f74a8680e8239b67e6a763"
          ]
        },
        "id": "apqP7iYEkmvl",
        "outputId": "c44f0e93-724e-4594-8ea0-aacb31cae46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "q4_k_m.gguf:   0%|          | 0.00/4.29G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84a8570ae41642a78495a29930b49247"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Rewatiramans/DeepSeek-R1-Distill-Qwen-7B-Q4-GGUF/commit/328c97b10ab1537b56ec3f60b37cfe8cb52c5eb5', commit_message='Upload Q4_K_M.gguf with huggingface_hub', commit_description='', oid='328c97b10ab1537b56ec3f60b37cfe8cb52c5eb5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Rewatiramans/DeepSeek-R1-Distill-Qwen-7B-Q4-GGUF', endpoint='https://huggingface.co', repo_type='model', repo_id='Rewatiramans/DeepSeek-R1-Distill-Qwen-7B-Q4-GGUF'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}